{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inceptionv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObIbDKNeV+HlWH54qEZa6d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0aaf3419c8e4508b1424c701ff225fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf97c4c2e5dd4cd8b07e07ae1de383ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e6be8bd6bcf4a218e36d20855dddf65",
              "IPY_MODEL_0ab6ac6531dd444aaa1bbbe90ee5785a"
            ]
          }
        },
        "cf97c4c2e5dd4cd8b07e07ae1de383ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e6be8bd6bcf4a218e36d20855dddf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84685d8966e94f4da9d472f281b156c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e671c6ad26c74d55afa16fc9b68bba24"
          }
        },
        "0ab6ac6531dd444aaa1bbbe90ee5785a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38456703491541b5831658feaa053849",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 15809756.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35174ca4648746b7882beef198a8c73d"
          }
        },
        "84685d8966e94f4da9d472f281b156c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e671c6ad26c74d55afa16fc9b68bba24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38456703491541b5831658feaa053849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35174ca4648746b7882beef198a8c73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O7GOEootwwy",
        "colab_type": "text"
      },
      "source": [
        "# Google's Inceptionv3 CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tgEQlltpMy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zE8kJvbqxpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1aec37d-00fa-46ac-b18c-7116f16309b1"
      },
      "source": [
        "# check if gpu present\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB1epf63rDGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z6ajPZorG7-",
        "colab_type": "text"
      },
      "source": [
        "# Datasets and transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsx_Ez0XrJ4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# earlier had used ToTensor() of \"transform\" to convert PIL image to tensor directly\n",
        "# This time using few more functions of \"transform\"\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "      transforms.RandomResizedCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "      transforms.RandomResizedCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quwBQIsQuyTZ",
        "colab_type": "text"
      },
      "source": [
        "Downloading and applying the transform object pipelined above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzzcqWjEuvJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "c0aaf3419c8e4508b1424c701ff225fb",
            "cf97c4c2e5dd4cd8b07e07ae1de383ab",
            "5e6be8bd6bcf4a218e36d20855dddf65",
            "0ab6ac6531dd444aaa1bbbe90ee5785a",
            "84685d8966e94f4da9d472f281b156c4",
            "e671c6ad26c74d55afa16fc9b68bba24",
            "38456703491541b5831658feaa053849",
            "35174ca4648746b7882beef198a8c73d"
          ]
        },
        "outputId": "30656081-ca22-4cc2-e278-2745f2832aea"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root = './data', train = True,\n",
        "                                        download = True, \n",
        "                                        transform = transform_train) # applying transform in this last line\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root = './data', train = False,\n",
        "                                        download = True, \n",
        "                                        transform = transform_test)\n",
        "                                        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0aaf3419c8e4508b1424c701ff225fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ASlJBqxvUar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn7k71LTvcbT",
        "colab_type": "text"
      },
      "source": [
        "10 classes in CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8hTd4ZFBVDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVrg2VWXEavY",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k-Ed_tOBf7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader, model):\n",
        "  total, correct = 0, 0\n",
        "  for data in dataloader:\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, pred = torch.max(outputs.data, 1) # index at which max value\n",
        "    total += labels.size(0)\n",
        "    correct += (pred == labels).sum().item()\n",
        "  return 100 * correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI3CZ2HMPVJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle = True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjAP3xYDsTaw",
        "colab_type": "text"
      },
      "source": [
        "# Inception Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48R34Yghsdu-",
        "colab_type": "text"
      },
      "source": [
        "Torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9ms6H48srd8",
        "colab_type": "text"
      },
      "source": [
        "Repeating modules with Parallel paths and dangling (auxillary outputs - useful during training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoWYyULNsVBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception = torchvision.models.inception_v3(pretrained = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5OTBYS6skqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(inception)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I9-J4q9s-g-",
        "colab_type": "text"
      },
      "source": [
        "InceptionA, Inception B, C, D, E (a class of those paralled layers) like BuildingBlock in ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNc1YeoitWvj",
        "colab_type": "text"
      },
      "source": [
        "NOte very very large network  \n",
        "InceptionAux to make sure gradients flow through"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y9OWh-Otl6Q",
        "colab_type": "text"
      },
      "source": [
        "Finally is fc (fully connected neural layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn_MVIhEs8H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in inception.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvuFY0_6udfp",
        "colab_type": "text"
      },
      "source": [
        "Change # of classes in \"auxillary\" and \"final\" outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnYxfpsqu0_x",
        "colab_type": "text"
      },
      "source": [
        "First, auxillary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRPkGLdVtwgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aux_in_features = inception.AuxLogits.fc.in_features\n",
        "inception.AuxLogits.fc = nn.Linear(aux_in_features, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_f2OAZat9gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in inception.parameters():\n",
        "  if(param.requires_grad):\n",
        "    print(param.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZsMEBlLu4sC",
        "colab_type": "text"
      },
      "source": [
        "Now output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_0JAmu8uIMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_features = inception.fc.in_features\n",
        "inception.fc = nn.Linear(in_features, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMdl9GylupLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in inception.parameters():\n",
        "  if(param.requires_grad):\n",
        "    print(param.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eA0jMsau6fi",
        "colab_type": "text"
      },
      "source": [
        "Shows that now both auxillary and final output are changed (# classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KONU5On7u_Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRvP6FGJvFYD",
        "colab_type": "text"
      },
      "source": [
        "Also, for inception input size is 299 x 299, so resize/transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RAQ2qcpvKX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85P_-sFWvheb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root = './data', train = True,\n",
        "                                        download = True, \n",
        "                                        transform = transform_train) # applying transform in this last line\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root = './data', train = False,\n",
        "                                        download = True, \n",
        "                                        transform = transform_test)\n",
        "                                        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij8Xud-cwJdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esz5NX9FwvXA",
        "colab_type": "text"
      },
      "source": [
        "### Training Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9_0sXwGwwwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception = inception.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(inception.parameters(), lr = 0.01) # stochastic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPCGqq_exL7X",
        "colab_type": "text"
      },
      "source": [
        "Slight change in evaluation: See in the code of inception, during forward pass, it returns both final and auxillary output, so you have to take the aux outputs too. (though you won't use them)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqmHDIyGw6JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_inception(dataloader, model):\n",
        "  total, correct = 0, 0\n",
        "  for data in dataloader:\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs, aux_outputs = model(inputs)\n",
        "    _, pred = torch.max(outputs.data, 1) # index at which max value\n",
        "    total += labels.size(0)\n",
        "    correct += (pred == labels).sum().item()\n",
        "  return 100 * correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OrrSg-vyCPH",
        "colab_type": "text"
      },
      "source": [
        "Changes in learning loop commented"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtq5Zi-HxgA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_epoch_arr = []\n",
        "max_epochs = 4\n",
        "\n",
        "n_iters = np.ceil(50000/batch_size)\n",
        "\n",
        "min_loss = 1000\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # one more output\n",
        "    outputs, aux_outputs = inception(inputs)\n",
        "    # sum up losses and then propagate (new feature in deep NNs)\n",
        "    # main weightage given to main loss (weightage = 1), and smaller weightage to previous ones (0.3)\n",
        "    loss = loss_fn(outputs, labels) + 0.3*loss_fn(aux_outptus, labels)\n",
        "\n",
        "    loss.backward() \n",
        "    opt.step() \n",
        "\n",
        "    if loss.item() < min_loss: \n",
        "      min_loss = loss.item() \n",
        "      best_model = copy.deepcopy(inception.state_dict())\n",
        "      print(\"Min loss %0.2f\" % min_loss)\n",
        "\n",
        "    if i%100 == 0:\n",
        "      print(\"Iteration: %d/%d, Loss: %0.2f\" % (i, n_iters, loss.item()))\n",
        "\n",
        "    del inputs, labels, outputs\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "  loss_epoch_arr.append(loss.item())\n",
        "\n",
        "  # change evaluation metric\n",
        "  print(\"Epoch: %d/%d, Test acc = %0.2f, Train acc = 0.2f\" %(\n",
        "      epoch, max_epochs,\n",
        "      evaluation_inception(testloader, inception), evaluation_inception(trainloader, inception)))\n",
        "  \n",
        "  plt.plot(loss_epoch_arr)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkGVIljXyAdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception.load_state_dict(best_model)\n",
        "print(evaluation(trainloader, resnet), evaluation(testloader, resnet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fntGXlYtyvVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}